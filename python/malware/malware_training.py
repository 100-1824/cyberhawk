# ===== CELL 1: Install Dependencies =====
#!pip install scikit-learn numpy pandas joblib xgboost -q
print("✓ Dependencies installed")

# ===== CELL 2: Training Code =====
import os
import sys
import json
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import joblib
import warnings
warnings.filterwarnings('ignore')

class MalwareMLTrainer:
    def __init__(self):
        self.model = None
        self.feature_names = [
            'file_size',
            'entropy',
            'section_count',
            'import_count',
            'export_count',
            'suspicious_apis',
            'suspicious_strings',
            'packer_detected',
            'digital_signature',
            'high_entropy_sections',
            'code_to_data_ratio',
            'writable_executable_sections',
            'dll_characteristics',
            'api_suspicious_score',
            'string_entropy'
        ]
    
    def create_synthetic_training_data(self):
        """Create synthetic training data with realistic characteristics"""
        print("[DATA] Creating synthetic training dataset...")
        
        np.random.seed(42)
        n_samples = 2000  # Increased dataset size
        
        # Benign files (50%)
        benign_samples = []
        for _ in range(n_samples // 2):
            features = [
                np.random.uniform(10.0, 500.0),      # file_size (KB)
                np.random.uniform(4.0, 6.5),         # entropy (normal)
                np.random.randint(3, 8),             # section_count
                np.random.randint(10, 50),           # import_count
                np.random.randint(0, 5),             # export_count
                np.random.randint(0, 3),             # suspicious_apis (few)
                np.random.randint(0, 5),             # suspicious_strings (few)
                0,                                    # packer_detected (no)
                np.random.choice([0, 1], p=[0.3, 0.7]),  # digital_signature (mostly yes)
                np.random.randint(0, 2),             # high_entropy_sections (few)
                np.random.uniform(0.3, 0.7),         # code_to_data_ratio (balanced)
                0,                                    # writable_executable_sections (no)
                np.random.randint(0, 2),             # dll_characteristics
                np.random.uniform(0.0, 0.3),         # api_suspicious_score (low)
                np.random.uniform(4.0, 6.0)          # string_entropy (normal)
            ]
            benign_samples.append(features)
        
        # Malware files (50%)
        malware_samples = []
        for _ in range(n_samples // 2):
            features = [
                np.random.uniform(5.0, 1000.0),      # file_size (varied)
                np.random.uniform(6.5, 8.0),         # entropy (high)
                np.random.randint(5, 15),            # section_count (more sections)
                np.random.randint(20, 100),          # import_count (many imports)
                np.random.randint(0, 3),             # export_count
                np.random.randint(5, 15),            # suspicious_apis (many)
                np.random.randint(10, 30),           # suspicious_strings (many)
                np.random.choice([0, 1], p=[0.4, 0.6]),  # packer_detected (often yes)
                np.random.choice([0, 1], p=[0.8, 0.2]),  # digital_signature (mostly no)
                np.random.randint(3, 8),             # high_entropy_sections (many)
                np.random.uniform(0.1, 0.4),         # code_to_data_ratio (low - packed)
                np.random.choice([0, 1], p=[0.5, 0.5]),  # writable_executable_sections
                np.random.randint(3, 6),             # dll_characteristics (unusual)
                np.random.uniform(0.6, 1.0),         # api_suspicious_score (high)
                np.random.uniform(6.5, 8.0)          # string_entropy (high)
            ]
            malware_samples.append(features)
        
        X = np.array(benign_samples + malware_samples)
        y = np.array([0] * len(benign_samples) + [1] * len(malware_samples))
        
        # Add realistic noise to reduce overfitting
        print("[DATA] Adding realistic noise to prevent overfitting...")
        noise = np.random.normal(0, 0.1, X.shape)
        X = X + noise
        X = np.clip(X, 0, None)  # Keep values positive
        
        # Add 3% label noise (mislabeled samples)
        noise_indices = np.random.choice(len(y), size=int(len(y) * 0.03), replace=False)
        y[noise_indices] = 1 - y[noise_indices]
        print(f"[DATA] Added noise to {len(noise_indices)} samples")
        
        # Shuffle data
        indices = np.random.permutation(len(X))
        X = X[indices]
        y = y[indices]
        
        print(f"[DATA] Created {len(X)} samples:")
        print(f"       - {len(benign_samples)} benign files")
        print(f"       - {len(malware_samples)} malware files")
        
        return X, y
    
    def train_model(self, X_train, y_train):
        """Train Gradient Boosting Classifier with regularization"""
        print("\n[TRAIN] Training Gradient Boosting Classifier...")
        print("[TRAIN] Hyperparameters (with regularization):")
        print("        - Estimators: 100")
        print("        - Max Depth: 5")
        print("        - Min Samples Split: 20")
        print("        - Min Samples Leaf: 10")
        print("        - Learning Rate: 0.1")
        
        self.model = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=5,              # Shallow trees to prevent overfitting
            min_samples_split=20,     # Increased to prevent overfitting
            min_samples_leaf=10,      # Increased to prevent overfitting
            learning_rate=0.1,
            subsample=0.8,            # Use 80% of samples per tree
            random_state=42
        )
        
        self.model.fit(X_train, y_train)
        print("[TRAIN] ✓ Model training completed")
    
    def evaluate_model(self, X_test, y_test):
        """Evaluate model with detailed metrics"""
        print("\n[EVAL] Evaluating model on test set...")
        
        y_pred = self.model.predict(X_test)
        y_proba = self.model.predict_proba(X_test)
        
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        cm = confusion_matrix(y_test, y_pred)
        
        print("\n" + "="*60)
        print("MODEL EVALUATION RESULTS")
        print("="*60)
        print(f"Accuracy:  {accuracy*100:.2f}%")
        print(f"Precision: {precision*100:.2f}%")
        print(f"Recall:    {recall*100:.2f}%")
        print(f"F1-Score:  {f1*100:.2f}%")
        print("\nConfusion Matrix:")
        print(f"                Predicted")
        print(f"              Benign  Malware")
        print(f"Actual Benign    {cm[0][0]:3d}      {cm[0][1]:3d}")
        print(f"       Malware   {cm[1][0]:3d}      {cm[1][1]:3d}")
        print("="*60)
        
        # Feature importance
        importances = self.model.feature_importances_
        indices = np.argsort(importances)[::-1]
        
        print("\nTop 10 Important Features:")
        for i in range(min(10, len(indices))):
            print(f"  {i+1}. {self.feature_names[indices[i]]}: {importances[indices[i]]:.4f}")
        
        # Calculate False Positive Rate
        tn, fp, fn, tp = cm.ravel()
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0
        
        print(f"\nFalse Positive Rate: {fpr*100:.2f}%")
        print(f"False Negative Rate: {fnr*100:.2f}%")
        
        return {
            'accuracy': float(accuracy),
            'precision': float(precision),
            'recall': float(recall),
            'f1_score': float(f1),
            'false_positive_rate': float(fpr),
            'false_negative_rate': float(fnr),
            'confusion_matrix': cm.tolist(),
            'feature_importance': {
                self.feature_names[i]: float(importances[i]) 
                for i in range(len(self.feature_names))
            }
        }
    
    def cross_validate(self, X, y):
        """Perform cross-validation"""
        print("\n[CROSS-VAL] Performing 5-fold cross-validation...")
        
        scores = cross_val_score(self.model, X, y, cv=5, scoring='accuracy')
        
        print(f"[CROSS-VAL] Cross-validation scores: {scores}")
        print(f"[CROSS-VAL] Mean accuracy: {scores.mean()*100:.2f}%")
        print(f"[CROSS-VAL] Std deviation: {scores.std()*100:.2f}%")
        
        return {
            'cv_scores': scores.tolist(),
            'cv_mean': float(scores.mean()),
            'cv_std': float(scores.std())
        }
    
    def save_model(self, path):
        """Save trained model"""
        joblib.dump(self.model, path)
        print(f"\n[SAVE] ✓ Model saved to: {path}")
    
    def save_metrics(self, metrics, path):
        """Save evaluation metrics"""
        with open(path, 'w') as f:
            json.dump(metrics, f, indent=2)
        print(f"[SAVE] ✓ Metrics saved to: {path}")

# ===== CELL 3: Train Model =====
print("\n" + "="*60)
print("CYBERHAWK MALWARE DETECTION - MODEL TRAINING")
print("="*60 + "\n")

trainer = MalwareMLTrainer()

# Create training data
X, y = trainer.create_synthetic_training_data()

# Split data
print("\n[SPLIT] Splitting into train/test sets (80/20)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"[SPLIT] Training samples: {len(X_train)}")
print(f"[SPLIT] Testing samples:  {len(X_test)}")

# Train model
trainer.train_model(X_train, y_train)

# Evaluate on test set
test_metrics = trainer.evaluate_model(X_test, y_test)

# Cross-validation
cv_metrics = trainer.cross_validate(X, y)

# Combine metrics
all_metrics = {**test_metrics, **cv_metrics}

# Save model and metrics
trainer.save_model('malware_model.pkl')
trainer.save_metrics(all_metrics, 'malware_model_metrics.json')

print("\n" + "="*60)
print("✓ TRAINING COMPLETE!")
print("="*60)

# ===== CELL 4: Download Files =====
from google.colab import files

print("\n[DOWNLOAD] Downloading model file...")
files.download('malware_model.pkl')

print("[DOWNLOAD] Downloading metrics file...")
files.download('malware_model_metrics.json')

print("\n✓ Files downloaded!")
print("\nNext steps:")
print("1. Place malware_model.pkl in: cyberhawk/python/malware/")
print("2. Place malware_model_metrics.json in: cyberhawk/assets/data/")