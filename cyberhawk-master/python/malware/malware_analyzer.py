#!/usr/bin/env python3
"""
CyberHawk Malware Behavioral Analyzer - Simplified Edition
Performs behavioral analysis without unreliable ML model
"""

import os
import sys
import json
import re
import argparse
from datetime import datetime
from pathlib import Path

# Configuration
CONFIG = {
    'DATA_DIR': 'assets/data',
    'UPLOADS_DIR': 'assets/data/malware_uploads',
}

class BehavioralAnalyzer:
    def __init__(self):
        self.reports_file = os.path.join(CONFIG['DATA_DIR'], 'malware_reports.json')
        
        # Behavioral patterns for detection
        self.api_patterns = {
            'Process Injection': {
                'apis': ['CreateRemoteThread', 'WriteProcessMemory', 'VirtualAllocEx',
                        'NtCreateThreadEx', 'RtlCreateUserThread', 'SetThreadContext'],
                'risk': 'critical'
            },
            'Code Injection': {
                'apis': ['LoadLibrary', 'GetProcAddress', 'VirtualAlloc',
                        'VirtualProtect', 'CreateThread'],
                'risk': 'high'
            },
            'Keylogging': {
                'apis': ['SetWindowsHookEx', 'GetAsyncKeyState', 'GetKeyState',
                        'RegisterHotKey', 'GetKeyboardState', 'GetRawInputData'],
                'risk': 'critical'
            },
            'Screen Capture': {
                'apis': ['BitBlt', 'GetDC', 'CreateCompatibleDC',
                        'CreateCompatibleBitmap', 'StretchBlt', 'GetDesktopWindow'],
                'risk': 'high'
            },
            'Network Activity': {
                'apis': ['InternetOpen', 'InternetConnect', 'HttpSendRequest',
                        'WSAStartup', 'socket', 'connect', 'send', 'recv'],
                'risk': 'medium'
            },
            'File System': {
                'apis': ['CreateFile', 'WriteFile', 'ReadFile',
                        'DeleteFile', 'MoveFile', 'CopyFile', 'FindFirstFile'],
                'risk': 'low'
            },
            'Registry': {
                'apis': ['RegOpenKey', 'RegSetValue', 'RegDeleteValue',
                        'RegCreateKey', 'RegQueryValue', 'RegEnumKey'],
                'risk': 'medium'
            },
            'Service Control': {
                'apis': ['CreateService', 'OpenService', 'StartService',
                        'ControlService', 'DeleteService', 'ChangeServiceConfig'],
                'risk': 'high'
            },
            'Persistence': {
                'apis': ['SetWindowsHookEx', 'RegSetValue', 'CreateService',
                        'WinExec', 'ShellExecute', 'CreateProcess'],
                'risk': 'high'
            },
            'Cryptography': {
                'apis': ['CryptEncrypt', 'CryptDecrypt', 'CryptAcquireContext',
                        'CryptCreateHash', 'CryptDeriveKey', 'CryptGenKey'],
                'risk': 'medium'
            }
        }
        
        self.suspicious_strings = {
            'Commands': {
                'patterns': ['cmd.exe', 'powershell', 'wscript', 'cscript',
                           'rundll32', 'regsvr32', 'mshta', 'certutil'],
                'risk': 'high'
            },
            'System': {
                'patterns': ['net user', 'net localgroup', 'schtasks', 'at.exe',
                           'taskkill', 'reg add', 'reg delete', 'sc create'],
                'risk': 'high'
            },
            'Credentials': {
                'patterns': ['password', 'passwd', 'pwd', 'credential',
                           'username', 'login', 'admin', 'root'],
                'risk': 'medium'
            },
            'Ransomware': {
                'patterns': ['encrypt', 'decrypt', 'bitcoin', 'wallet',
                           'ransom', 'payment', '.locked', '.encrypted'],
                'risk': 'critical'
            },
            'Network': {
                'patterns': ['http://', 'https://', 'ftp://', 'tcp://',
                           'udp://', 'tor', 'onion', 'proxy'],
                'risk': 'medium'
            },
            'Malware': {
                'patterns': ['backdoor', 'rootkit', 'trojan', 'keylog',
                           'inject', 'payload', 'exploit', 'shellcode'],
                'risk': 'critical'
            }
        }
    
    def analyze_file(self, file_id, filepath):
        """Perform behavioral analysis"""
        print(f"[ANALYZE] Starting behavioral analysis: {filepath}")
        
        try:
            with open(filepath, 'rb') as f:
                file_data = f.read()
            
            # Extract and analyze strings
            strings = self.extract_strings(file_data)
            
            # Analyze API calls
            api_behaviors = self.analyze_api_calls(file_data)
            
            # Analyze suspicious strings
            string_behaviors = self.analyze_strings(strings)
            
            # Analyze file structure
            structure_analysis = self.analyze_structure(file_data)
            
            # Calculate threat indicators
            threat_indicators = self.calculate_threat_indicators(
                api_behaviors, string_behaviors, structure_analysis
            )
            
            # Compile results
            analysis_result = {
                'file_id': file_id,
                'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'api_behaviors': api_behaviors,
                'string_behaviors': string_behaviors,
                'structure_analysis': structure_analysis,
                'extracted_strings': strings[:100],
                'threat_indicators': threat_indicators
            }
            
            # Update report with behavioral analysis
            self.update_report(file_id, analysis_result)
            
            print("[ANALYZE] ✓ Behavioral analysis complete")
            print(f"[ANALYZE] Threat Score: {threat_indicators['threat_score']}/100")
            print(f"[ANALYZE] Risk Level: {threat_indicators['risk_level']}")
            
            return analysis_result
            
        except Exception as e:
            print(f"[ERROR] Analysis failed: {e}")
            return None
    
    def extract_strings(self, data, min_length=4):
        """Extract printable strings from binary data"""
        strings = []
        current_string = []
        
        # Limit analysis to first 512KB for performance
        data_sample = data[:524288]
        
        for byte in data_sample:
            if 32 <= byte <= 126:  # Printable ASCII
                current_string.append(chr(byte))
            else:
                if len(current_string) >= min_length:
                    string = ''.join(current_string)
                    if len(string) <= 200:  # Limit string length
                        strings.append(string)
                current_string = []
        
        # Add final string
        if len(current_string) >= min_length:
            strings.append(''.join(current_string))
        
        # Return unique strings
        return list(set(strings))[:1000]
    
    def analyze_api_calls(self, data):
        """Analyze API call patterns"""
        behaviors = []
        data_sample = data[:1048576]  # Analyze first 1MB
        
        for behavior_type, info in self.api_patterns.items():
            detected_apis = []
            
            for api in info['apis']:
                if api.encode() in data_sample or api.encode('utf-16le') in data_sample:
                    detected_apis.append(api)
            
            if detected_apis:
                severity = self._get_severity(info['risk'], len(detected_apis))
                
                behaviors.append({
                    'type': behavior_type,
                    'severity': severity,
                    'risk': info['risk'],
                    'detected_apis': detected_apis,
                    'count': len(detected_apis),
                    'description': f"Detected {len(detected_apis)} APIs related to {behavior_type.lower()}"
                })
        
        return behaviors
    
    def analyze_strings(self, strings):
        """Analyze extracted strings for suspicious patterns"""
        behaviors = []
        
        for category, info in self.suspicious_strings.items():
            detected = []
            
            for string in strings:
                string_lower = string.lower()
                for pattern in info['patterns']:
                    if pattern.lower() in string_lower:
                        if string not in detected:
                            detected.append(string)
                            if len(detected) >= 20:  # Limit per category
                                break
                if len(detected) >= 20:
                    break
            
            if detected:
                severity = self._get_severity(info['risk'], len(detected))
                
                behaviors.append({
                    'category': category,
                    'severity': severity,
                    'risk': info['risk'],
                    'detected_strings': detected[:10],
                    'count': len(detected),
                    'description': f"Found {len(detected)} {category.lower()} indicators"
                })
        
        return behaviors
    
    def analyze_structure(self, data):
        """Analyze file structure"""
        analysis = {
            'is_pe': False,
            'is_packed': False,
            'has_overlay': False,
            'suspicious_sections': [],
            'file_format': 'Unknown'
        }
        
        # Check for common file formats
        if data[:2] == b'MZ':
            analysis['is_pe'] = True
            analysis['file_format'] = 'PE (Windows Executable)'
            
            # Check for packing indicators
            packers = {
                b'UPX': 'UPX',
                b'PECompact': 'PECompact',
                b'ASPack': 'ASPack',
                b'Themida': 'Themida',
                b'VMProtect': 'VMProtect',
                b'MPRESS': 'MPRESS',
                b'Petite': 'Petite',
                b'FSG': 'FSG'
            }
            
            for signature, name in packers.items():
                if signature in data[:8192]:
                    analysis['is_packed'] = True
                    analysis['packer_name'] = name
                    break
            
            # Check for suspicious section names
            try:
                pe_offset = int.from_bytes(data[0x3C:0x40], 'little')
                if pe_offset + 0x18 < len(data):
                    section_count = int.from_bytes(data[pe_offset+6:pe_offset+8], 'little')
                    
                    # Look for unusual section names
                    suspicious_names = [b'UPX', b'.packed', b'.crypto', b'.enc']
                    for name in suspicious_names:
                        if name in data[pe_offset:pe_offset+2048]:
                            analysis['suspicious_sections'].append(name.decode('utf-8', errors='ignore'))
            except:
                pass
            
            # Check for overlay data
            if len(data) > 500000:  # Files over 500KB might have overlay
                analysis['has_overlay'] = True
        
        elif data[:4] == b'\x7fELF':
            analysis['file_format'] = 'ELF (Linux Executable)'
        elif data[:4] == b'%PDF':
            analysis['file_format'] = 'PDF'
        elif data[:2] == b'PK':
            analysis['file_format'] = 'ZIP/Office Document'
        
        return analysis
    
    def _get_severity(self, risk, count):
        """Determine severity based on risk level and count"""
        if risk == 'critical':
            return 'high'
        elif risk == 'high':
            return 'high' if count > 3 else 'medium'
        elif risk == 'medium':
            return 'medium' if count > 5 else 'low'
        else:
            return 'low'
    
    def calculate_threat_indicators(self, api_behaviors, string_behaviors, structure_analysis):
        """Calculate overall threat indicators"""
        indicators = {
            'threat_score': 0,
            'risk_level': 'LOW',
            'primary_threats': [],
            'recommendations': []
        }
        
        # Score from API behaviors
        for behavior in api_behaviors:
            if behavior['risk'] == 'critical':
                indicators['threat_score'] += 10
                indicators['primary_threats'].append(behavior['type'])
            elif behavior['risk'] == 'high':
                indicators['threat_score'] += 7
                if behavior['count'] > 3:
                    indicators['primary_threats'].append(behavior['type'])
            elif behavior['risk'] == 'medium':
                indicators['threat_score'] += 4
        
        # Score from string behaviors
        for behavior in string_behaviors:
            if behavior['risk'] == 'critical':
                indicators['threat_score'] += 8
                indicators['primary_threats'].append(f"{behavior['category']} Strings")
            elif behavior['risk'] == 'high':
                indicators['threat_score'] += 5
            elif behavior['risk'] == 'medium':
                indicators['threat_score'] += 3
        
        # Score from structure
        if structure_analysis['is_packed']:
            indicators['threat_score'] += 10
            indicators['recommendations'].append(
                f"File is packed with {structure_analysis.get('packer_name', 'unknown packer')} - consider unpacking for deeper analysis"
            )
        
        if structure_analysis['has_overlay']:
            indicators['threat_score'] += 5
            indicators['recommendations'].append("File contains overlay data - may hide additional payload")
        
        if structure_analysis['suspicious_sections']:
            indicators['threat_score'] += 7
            indicators['recommendations'].append("Suspicious PE sections detected")
        
        # Cap score at 100
        indicators['threat_score'] = min(indicators['threat_score'], 100)
        
        # Determine risk level
        if indicators['threat_score'] >= 60:
            indicators['risk_level'] = 'CRITICAL'
        elif indicators['threat_score'] >= 40:
            indicators['risk_level'] = 'HIGH'
        elif indicators['threat_score'] >= 20:
            indicators['risk_level'] = 'MEDIUM'
        else:
            indicators['risk_level'] = 'LOW'
        
        # Generate recommendations based on detected threats
        if 'Process Injection' in indicators['primary_threats']:
            indicators['recommendations'].append("Process injection capabilities detected - isolate and monitor")
        
        if 'Keylogging' in indicators['primary_threats']:
            indicators['recommendations'].append("Keylogging capabilities detected - check for data theft")
        
        if 'Network Activity' in [b['type'] for b in api_behaviors]:
            indicators['recommendations'].append("Network capabilities detected - monitor network traffic")
        
        if 'Ransomware Strings' in indicators['primary_threats']:
            indicators['recommendations'].append("Ransomware indicators detected - backup critical data immediately")
        
        # Ensure we have some recommendations
        if not indicators['recommendations']:
            if indicators['risk_level'] in ['CRITICAL', 'HIGH']:
                indicators['recommendations'].append("Execute in isolated sandbox environment only")
            elif indicators['risk_level'] == 'MEDIUM':
                indicators['recommendations'].append("Monitor file behavior in controlled environment")
            else:
                indicators['recommendations'].append("Standard security practices recommended")
        
        return indicators
    
    def update_report(self, file_id, analysis):
        """Update existing report with behavioral analysis"""
        try:
            if not os.path.exists(self.reports_file):
                print("[WARN] Reports file not found")
                return
            
            with open(self.reports_file, 'r') as f:
                content = f.read()
                if not content:
                    reports = []
                else:
                    reports = json.loads(content)
            
            # Find and update report
            updated = False
            for report in reports:
                if report.get('file_id') == file_id:
                    # Merge behavioral analysis into existing report
                    report['behavioral_analysis'] = analysis
                    
                    # Update behaviors list
                    if 'behaviors' not in report:
                        report['behaviors'] = []
                    
                    # Add API behaviors
                    for api_behavior in analysis['api_behaviors']:
                        report['behaviors'].append({
                            'type': api_behavior['type'],
                            'severity': api_behavior['severity'],
                            'description': api_behavior['description']
                        })
                    
                    # Add significant string behaviors
                    for string_behavior in analysis['string_behaviors']:
                        if string_behavior['severity'] in ['high', 'medium']:
                            report['behaviors'].append({
                                'type': f"{string_behavior['category']} Detection",
                                'severity': string_behavior['severity'],
                                'description': string_behavior['description']
                            })
                    
                    # Update threat indicators
                    report['threat_indicators'] = analysis['threat_indicators']
                    
                    # Update strings if more were found
                    if 'strings' not in report or not report['strings']:
                        report['strings'] = analysis['extracted_strings'][:50]
                    
                    updated = True
                    break
            
            if updated:
                with open(self.reports_file, 'w') as f:
                    json.dump(reports, f, indent=2)
                
                print("[UPDATE] ✓ Report updated with behavioral analysis")
            else:
                print(f"[WARN] Report not found for file ID: {file_id}")
            
        except Exception as e:
            print(f"[ERROR] Failed to update report: {e}")
    
    def generate_detailed_report(self, file_id):
        """Generate detailed analysis report"""
        try:
            with open(self.reports_file, 'r') as f:
                reports = json.load(f)
            
            for report in reports:
                if report.get('file_id') == file_id:
                    print("\n" + "="*70)
                    print("DETAILED BEHAVIORAL ANALYSIS REPORT")
                    print("="*70)
                    print(f"File: {report.get('filename', 'Unknown')}")
                    print(f"Threat Level: {report.get('threat_level', 'UNKNOWN')}")
                    
                    if 'behavioral_analysis' in report:
                        analysis = report['behavioral_analysis']
                        
                        print("\n--- API Behaviors ---")
                        for behavior in analysis.get('api_behaviors', []):
                            print(f"  [{behavior['severity'].upper()}] {behavior['type']}")
                            print(f"    Risk: {behavior['risk']}")
                            print(f"    Detected: {behavior['count']} APIs")
                            print(f"    {behavior['description']}")
                        
                        print("\n--- String Behaviors ---")
                        for behavior in analysis.get('string_behaviors', []):
                            print(f"  [{behavior['severity'].upper()}] {behavior['category']}")
                            print(f"    Risk: {behavior['risk']}")
                            print(f"    Found: {behavior['count']} indicators")
                            if behavior.get('detected_strings'):
                                print(f"    Examples: {', '.join(behavior['detected_strings'][:3])}")
                        
                        print("\n--- Structure Analysis ---")
                        structure = analysis.get('structure_analysis', {})
                        print(f"  File Format: {structure.get('file_format', 'Unknown')}")
                        print(f"  Is Packed: {'Yes - ' + structure.get('packer_name', 'Unknown') if structure.get('is_packed') else 'No'}")
                        print(f"  Has Overlay: {'Yes' if structure.get('has_overlay') else 'No'}")
                        if structure.get('suspicious_sections'):
                            print(f"  Suspicious Sections: {', '.join(structure['suspicious_sections'])}")
                        
                        print("\n--- Threat Indicators ---")
                        indicators = analysis.get('threat_indicators', {})
                        print(f"  Threat Score: {indicators.get('threat_score', 0)}/100")
                        print(f"  Risk Level: {indicators.get('risk_level', 'UNKNOWN')}")
                        
                        if indicators.get('primary_threats'):
                            print(f"\n  Primary Threats:")
                            for threat in indicators['primary_threats']:
                                print(f"    • {threat}")
                        
                        if indicators.get('recommendations'):
                            print(f"\n  Recommendations:")
                            for rec in indicators['recommendations']:
                                print(f"    • {rec}")
                    
                    print("="*70 + "\n")
                    return report
            
            print(f"[ERROR] Report not found for file ID: {file_id}")
            return None
            
        except Exception as e:
            print(f"[ERROR] Failed to generate report: {e}")
            return None

def main():
    parser = argparse.ArgumentParser(description='CyberHawk Behavioral Analyzer')
    parser.add_argument('--file-id', required=True, help='File ID to analyze')
    parser.add_argument('--behavioral', action='store_true', help='Run behavioral analysis')
    parser.add_argument('--report', action='store_true', help='Generate detailed report')
    args = parser.parse_args()
    
    analyzer = BehavioralAnalyzer()
    
    print("=" * 70)
    print("CYBERHAWK BEHAVIORAL ANALYZER - ENHANCED EDITION")
    print("=" * 70)
    print("Analysis Modules:")
    print("  ✓ API Call Detection")
    print("  ✓ String Pattern Analysis")
    print("  ✓ Structure Analysis")
    print("  ✓ Packer Detection")
    print("  ✓ Threat Scoring")
    print("=" * 70 + "\n")
    
    # Find file
    file_id = args.file_id
    uploads_dir = CONFIG['UPLOADS_DIR']
    
    target_file = None
    if os.path.exists(uploads_dir):
        for filename in os.listdir(uploads_dir):
            if filename.startswith(file_id + '_'):
                target_file = os.path.join(uploads_dir, filename)
                break
    
    if not target_file or not os.path.exists(target_file):
        print(f"[ERROR] File not found for ID: {file_id}")
        sys.exit(1)
    
    # Run analysis
    if args.behavioral:
        result = analyzer.analyze_file(file_id, target_file)
        if result:
            print(f"\n[SUCCESS] Behavioral analysis complete")
    
    if args.report:
        analyzer.generate_detailed_report(file_id)

if __name__ == '__main__':
    main()